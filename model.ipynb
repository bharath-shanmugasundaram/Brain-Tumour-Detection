{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision._utils as util\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import sklearn.model_selection as sc\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a53453",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/no'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m X = []\n\u001b[32m      4\u001b[39m Y = []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m foldername \u001b[38;5;129;01min\u001b[39;00m os.listdir(folder_path):\n\u001b[32m      9\u001b[39m     img = (cv.imread(\u001b[33m\"\u001b[39m\u001b[33m/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/no/\u001b[39m\u001b[33m\"\u001b[39m+foldername))    \n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/no'"
     ]
    }
   ],
   "source": [
    "folder_path = \"/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/no\"\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "print(len(os.listdir(folder_path)))\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    \n",
    "    img = (cv.imread(\"/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/no/\"+foldername))    \n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    X.append(img)\n",
    "    Y.append(0)\n",
    "\n",
    "X_test = X[90:]\n",
    "X = X[:90]\n",
    "\n",
    "Y_test = Y[90:]\n",
    "Y = Y[:90]\n",
    "\n",
    "currx=[]\n",
    "curry =[]\n",
    "folder_path = \"/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/yes\"\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    img = (cv.imread(\"/Users/bhara-zstch1566/CNN/Project/Resnet real/archive-3/brain_tumor_dataset/yes/\"+foldername))\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    currx.append(img)\n",
    "    curry.append(1)\n",
    "\n",
    "X_test += currx[90:]\n",
    "currx = currx[:90]\n",
    "\n",
    "Y_test += curry[90:]\n",
    "curry = curry[:90]\n",
    "\n",
    "X += currx\n",
    "Y += curry\n",
    "\n",
    "print(len(os.listdir(folder_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3143f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 180\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                   \n",
    "    transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
    "    transforms.Resize((64, 64)),                  # resize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])   # normalize grayscale\n",
    "])\n",
    "def ta(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = transform(x[i])\n",
    "    return x\n",
    "X = ta(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80dc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a92e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180, 1, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= t.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debb74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 1, 64, 64]) torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262a33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainTumor,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,3,5,1)\n",
    "        self.conv2 = nn.Conv2d(3,256,5,2)\n",
    "        self.max_pool = nn.MaxPool2d(3,2)\n",
    "        self.conv3 = nn.Conv2d(256,256,3)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = F.relu(self.conv3(F.relu(self.conv3(x))))\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4a2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrainTumor()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b1d499",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset = \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m train_loader = DataLoader(train_dataset, batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/torch/utils/data/dataset.py:201\u001b[39m, in \u001b[36mTensorDataset.__init__\u001b[39m\u001b[34m(self, *tensors)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *tensors: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mSize mismatch between tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.13/lib/python/site-packages/torch/utils/data/dataset.py:202\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *tensors: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m         \u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m(\u001b[32m0\u001b[39m) == tensor.size(\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[32m    203\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mSize mismatch between tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X,Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8ae41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if t.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8b18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.7360\n",
      "Epoch [2/5], Loss: 0.6963\n",
      "Epoch [3/5], Loss: 0.6642\n",
      "Epoch [4/5], Loss: 0.7245\n",
      "Epoch [5/5], Loss: 0.6469\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running = 0.0\n",
    "    for img,label in train_loader:\n",
    "        img , label = img.to(device),label.to(device)\n",
    "        y_pred = model(img)\n",
    "        loss = criterion(y_pred,label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running +=loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{5}], Loss: {running / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9273dfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zm/gf8ny5z13m70t3shtcspf3rh0000gp/T/ipykernel_38358/4044436238.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test = t.tensor(Y_test)\n"
     ]
    }
   ],
   "source": [
    "Y_test = t.tensor(Y_test)\n",
    "X_test = ta(X_test)\n",
    "X_test = t.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ded632a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test,Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2aa429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Accuracy: 79.45%\n"
     ]
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    ttotal =0\n",
    "    tcet = 0\n",
    "    for img,label in test_loader:\n",
    "        img ,label = img.to(device),label.to(device)\n",
    "        y_pred = model(img)\n",
    "        _,predicted = t.max(y_pred.data, 1)\n",
    "        ttotal += label.size(0)\n",
    "        tcet += (predicted == label).sum().item()\n",
    "    print(f\"Accuracy Accuracy: {100*tcet/ttotal:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52cfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
